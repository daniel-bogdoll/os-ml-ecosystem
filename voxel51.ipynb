{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.utils.random as four\n",
    "\n",
    "from fiftyone.utils.huggingface import load_from_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from Hugging Face Hub\n",
    "# https://huggingface.co/datasets/Voxel51/fisheye8k\n",
    "dataset = load_from_hub(\"Voxel51/fisheye8k\", name=\"fisheye8k-100\", max_samples=100, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small dataset has only train split. Generate val and test splits\n",
    "tags = dataset.count_sample_tags()\n",
    "print(f\"Sample splits:{tags}\")\n",
    "if \"test\" not in tags and \"val\" not in tags:\n",
    "    dataset.untag_samples([\"train\"])\n",
    "    four.random_split(dataset, {\"train\": 0.6, \"test\": 0.2, \"val\": 0.2})\n",
    "    tags = dataset.count_sample_tags()\n",
    "    print(f\"Modified sample splits:{tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over samples\n",
    "for sample in dataset:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the values you are setting can be described by a fiftyone.core.expressions.ViewExpression applied to the existing dataset contents, then consider using set_field() + save() for an even more efficient alternative to explicitly iterating over the dataset or calling values() + set_values() to perform the update in-memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and visualize image embeddings\n",
    "model_embeddings = foz.load_zoo_model(\"mobilenet-v2-imagenet-torch\")\n",
    "fob.compute_visualization(\n",
    "    dataset,\n",
    "    model=model_embeddings,\n",
    "    method=\"tsne\",\n",
    "    brain_key=\"mobilenet_tsne\",\n",
    "    num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and visualize detection embeddings\n",
    "model_embeddings = foz.load_zoo_model(\"mobilenet-v2-imagenet-torch\")\n",
    "fob.compute_visualization(\n",
    "    dataset,\n",
    "    patches_field=\"detections\",\n",
    "    model=model_embeddings,\n",
    "    method=\"tsne\",\n",
    "    brain_key=\"mobilenet_tsne_detections\",\n",
    "    num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Shot Object Detection based on existing object classes\n",
    "# Models from Hugging Face: https://huggingface.co/models?pipeline_tag=zero-shot-object-detection&library=transformers&sort=trending\n",
    "dataset_classes = dataset.default_classes\n",
    "print(f\"Object classes in dataset: {dataset_classes}\")\n",
    "\n",
    "# Grounding DINO\n",
    "model_zero_shot_grounding_dino = foz.load_zoo_model(\n",
    "    \"zero-shot-detection-transformer-torch\",\n",
    "    name_or_path=\"IDEA-Research/grounding-dino-base\",\n",
    "    classes=dataset_classes,\n",
    ")\n",
    "dataset.apply_model(model_zero_shot_grounding_dino, label_field=\"grounding_dino\", confidence_thresh=0.2, progress=True)\n",
    "\n",
    "# OwlV2\n",
    "model_zero_shot_owlv2 = foz.load_zoo_model(\n",
    "    \"zero-shot-detection-transformer-torch\",\n",
    "    name_or_path=\"google/owlv2-base-patch16-ensemble\",\n",
    "    classes=dataset_classes,\n",
    ")\n",
    "dataset.apply_model(model_zero_shot_owlv2, label_field=\"owlv2\", confidence_thresh=0.2, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate detections\n",
    "dataset.evaluate_detections(\n",
    "    \"grounding_dino\",\n",
    "    gt_field=\"detections\",\n",
    "    eval_key=\"eval_grounding_dino\",\n",
    "    compute_mAP=True,\n",
    ")\n",
    "\n",
    "dataset.evaluate_detections(\n",
    "    \"owlv2\",\n",
    "    gt_field=\"detections\",\n",
    "    eval_key=\"eval_owlv2\",\n",
    "    compute_mAP=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch Voxel51 GUI\n",
    "fo.launch_app(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
