{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from utils.dataset_loader import FiftyOneTorchDatasetCOCO, TorchToHFDatasetCOCO\n",
    "from transformers import AutoProcessor, AutoModelForObjectDetection, EarlyStoppingCallback, Trainer, TrainingArguments\n",
    "from datasets import Split\n",
    "import numpy as np\n",
    "import torch\n",
    "from functools import partial\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset conversion into Hugging Face format\n",
    "dataset_v51 = fo.load_dataset(\"fisheye8k-100\")\n",
    "dataset_torch = FiftyOneTorchDatasetCOCO(dataset_v51, gt_field=\"detections\")\n",
    "converter_torch2hf = TorchToHFDatasetCOCO(dataset_torch)\n",
    "dataset_hf = converter_torch2hf.convert()\n",
    "\n",
    "# Small dataset has only train split. Split into train, test, val\n",
    "train_test_split = dataset_hf[\"train\"].train_test_split(test_size=0.4)\n",
    "test_val_split = train_test_split[\"test\"].train_test_split(test_size=0.5)\n",
    "dataset_hf[\"train\"] = train_test_split[\"train\"]\n",
    "dataset_hf[\"test\"] = test_val_split[\"train\"]\n",
    "dataset_hf[\"validation\"] = test_val_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Mapping from ID to Name\n",
    "classes = dataset_v51.default_classes\n",
    "id2label = {i: class_name for i, class_name in enumerate(classes)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Detection Finetuning\n",
    "# https://huggingface.co/docs/transformers/en/tasks/object_detection\n",
    "\n",
    "MODEL_NAME = \"microsoft/conditional-detr-resnet-50\"\n",
    "MAX_SIZE = 512 # If tiny GPU memory\n",
    "\n",
    "# Preprocess setup for Hugging Face\n",
    "image_processor = AutoProcessor.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    size={\"max_height\": MAX_SIZE, \"max_width\": MAX_SIZE},\n",
    "    do_pad=True,\n",
    "    pad_size={\"height\": MAX_SIZE, \"width\": MAX_SIZE})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_processor expects the annotations to be in the following format: {'image_id': int, 'annotations': List[Dict]}, where each dictionary is a COCO object annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_batch(\n",
    "    batch,\n",
    "    image_processor,\n",
    "    return_pixel_mask=False,\n",
    "):\n",
    "    images = []\n",
    "    annotations = []\n",
    "\n",
    "    for image_path, annotation in zip(batch[\"image_path\"], batch[\"objects\"]):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image_np = np.array(image)\n",
    "        images.append(image_np)\n",
    "\n",
    "        coco_annotations = []\n",
    "        for i, bbox in enumerate(annotation[\"bbox\"]):\n",
    "            coco_annotation = {\n",
    "                \"image_id\": annotation[\"image_id\"],\n",
    "                \"bbox\": bbox,\n",
    "                \"category_id\": annotation[\"category_id\"][i],\n",
    "                \"area\": annotation[\"area\"][i],\n",
    "                \"iscrowd\": 0,\n",
    "            }\n",
    "            coco_annotations.append(coco_annotation)\n",
    "        detr_annotation = {\n",
    "            \"image_id\": annotation[\"image_id\"],\n",
    "            \"annotations\": coco_annotations,\n",
    "        }\n",
    "        annotations.append(detr_annotation)\n",
    "\n",
    "        # Apply the image processor transformations: resizing, rescaling, normalization\n",
    "        result = image_processor(\n",
    "            images=images, annotations=annotations, return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "    if not return_pixel_mask:\n",
    "        result.pop(\"pixel_mask\", None)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function for batching data during training and inference.\"\"\"\n",
    "    data = {}\n",
    "    data[\"pixel_values\"] = torch.stack([x[\"pixel_values\"] for x in batch])\n",
    "    data[\"labels\"] = [x[\"labels\"] for x in batch]\n",
    "    if \"pixel_mask\" in batch[0]:\n",
    "        data[\"pixel_mask\"] = torch.stack([x[\"pixel_mask\"] for x in batch])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_transform_batch = partial(\n",
    "            transform_batch,\n",
    "            image_processor=image_processor,\n",
    "        )\n",
    "\n",
    "dataset_hf[Split.TRAIN] = dataset_hf[Split.TRAIN].with_transform(\n",
    "            split_transform_batch)\n",
    "dataset_hf[Split.VALIDATION] = dataset_hf[Split.VALIDATION].with_transform(\n",
    "            split_transform_batch)\n",
    "dataset_hf[Split.TEST] = dataset_hf[Split.TEST].with_transform(\n",
    "            split_transform_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    run_name=MODEL_NAME,\n",
    "    num_train_epochs=12,\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=16,\n",
    "    auto_find_batch_size=True,\n",
    "    dataloader_num_workers=8,\n",
    "    learning_rate=5e-05,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    weight_decay=0.0001,\n",
    "    max_grad_norm=0.01,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"best\",\n",
    "    save_total_limit=1,\n",
    "    remove_unused_columns=False,\n",
    "    eval_do_concat_batches=False,\n",
    "    save_safetensors=False,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=5,\n",
    "    early_stopping_threshold=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_hf[Split.TRAIN],\n",
    "    eval_dataset=dataset_hf[Split.VALIDATION],\n",
    "    tokenizer=image_processor,\n",
    "    data_collator=collate_fn,\n",
    "    callbacks=[early_stopping_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(eval_dataset=dataset_hf[Split.TEST])\n",
    "print(f\"Model training completed. Evaluation results: {metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
